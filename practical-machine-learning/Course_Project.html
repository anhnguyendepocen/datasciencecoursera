<!DOCTYPE html><html><head><meta charset="utf-8"><title>Practical Machine Learning Course Project</title><style></style></head><body>
<h1 id="practical-machine-learning-course-project">Practical Machine Learning Course Project</h1>
<p>Author: Mike Silva<br>Date: January 2015  </p>
<h2 id="background">Background</h2>
<p><img src="Course_Project_files/figure-html/image-file.png" align="left"/>
Six young health participants were asked to perform one set of 10 repetitions of the unilateral dumbbell biceps curl in five different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E). These activities were monitored with on-body wearable accelerometers.<br/>
The task that I intend to preform is to develop a model that predicts what activity is being preformed based on the data that was collected, and use this model to classify twenty cases.  I will accomplish this by selecting the model that predicts with the highest degree of accuracy.</p>
<h2 id="feature-selection">Feature Selection</h2>
<p>I begin the process by loading the libraries I will need throughout the analysis.  As I want my research to be reproducible I will set the random number generation seed to 3.14:</p>
<pre><code class="lang-r"><span class="hljs-keyword">library</span>(caret)
<span class="hljs-keyword">library</span>(rattle)
set.seed(<span class="hljs-number">3.14</span>)
</code></pre>
<p>Next I download the data if it doesn&#39;t exist in the working directory:</p>
<pre><code class="lang-r">training.file &lt;- <span class="hljs-string">'pml-training.csv'</span>
<span class="hljs-keyword">if</span>(!file.exists(training.file)){
  download.file(<span class="hljs-string">'http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv'</span>, training.file)
}
testing.file &lt;- <span class="hljs-string">'pml-testing.csv'</span>
<span class="hljs-keyword">if</span>(!file.exists(testing.file)){
  download.file(<span class="hljs-string">'http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv'</span>, testing.file)
}
</code></pre>
<p>The data has missing values and excel error messages.  I cleaned these up and standardized the missing values as I load the data into the environment:</p>
<pre><code class="lang-r">training &lt;- read.csv(training.file, na.strings=c(<span class="hljs-string">'NA'</span>,<span class="hljs-string">'#DIV/0!'</span>,<span class="hljs-string">''</span>))
testing &lt;- read.csv(testing.file, na.strings=c(<span class="hljs-string">'NA'</span>,<span class="hljs-string">'#DIV/0!'</span>,<span class="hljs-string">''</span>))
</code></pre>
<p>Initially there are 160 features.  This is too many to create a useful prediction model so I determined I needed to remove some of the features.  I removed all features that have are nothing but missing values:</p>
<pre><code class="lang-r">training &lt;- training[,colSums(is.na(training)) == <span class="hljs-number">0</span>]
testing &lt;- testing[,colSums(is.na(testing)) == <span class="hljs-number">0</span>]
</code></pre>
<p>After this step I am left with 60 features.  Next I deleted the first 7 features (X, user_name, raw_timestamp_part_1, raw_timestamp_part_2, cvtd_timestamp, new_window, num_window) as they are meta data and not useful in forming a prediction model:</p>
<pre><code class="lang-r">training &lt;- training[, -c(<span class="hljs-number">1</span>:<span class="hljs-number">7</span>)]
testing &lt;- testing[, -c(<span class="hljs-number">1</span>:<span class="hljs-number">7</span>)]
</code></pre>
<p>I am now left with a pool of 53 possible features for inclusion in the prediction model.  A list of the feature and a sample of the data is given in the appendix.</p>
<h2 id="partitioning-data-set">Partitioning Data Set</h2>
<p>The data set that I am going to create my prediction model from contains 19622 observations.  In order to cross validate the models I partitioned this data set into two subsets.  I used 60% of the data for model training and 40% for cross validation.</p>
<pre><code class="lang-r">subset &lt;- createDataPartition(y=training$classe, p=<span class="hljs-number">0.6</span>, list=<span class="hljs-literal">FALSE</span>)
subset.for.training &lt;- training[subset,]
subset.for.testing &lt;- training[-subset,]
</code></pre>
<h2 id="modelling-approaches">Modelling Approaches</h2>
<h3 id="recursive-partitioning-and-regression-trees">Recursive Partitioning and Regression Trees</h3>
<p>I selected this approach as a way to form a baseline.  I did not expect this to provide a reliable prediction model.  However I needed something to compare the other models against.</p>
<pre><code class="lang-r">rpart.fit &lt;- train(classe ~ ., data=subset.for.training, method=<span class="hljs-string">'rpart'</span>)
predict.rpart &lt;- predict(rpart.fit, subset.for.testing)
fancyRpartPlot(rpart.fit $finalModel)
</code></pre>
<p><img src="Course_Project_files/figure-html/unnamed-chunk-8-1.png" alt=""> </p>
<pre><code class="lang-r">rpart.cm &lt;- confusionMatrix(predict.rpart, subset.for.testing$classe)
rpart.cm
</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 2004  623  634  586  169
##          B   39  533   38  238  196
##          C  154  362  696  462  376
##          D    0    0    0    0    0
##          E   35    0    0    0  701
## 
## Overall Statistics
##                                           
##                Accuracy : 0.5014          
##                  95% CI : (0.4903, 0.5125)
##     No Information Rate : 0.2845          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.349           
##  Mcnemar&#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.8978  0.35112  0.50877   0.0000  0.48613
## Specificity            0.6416  0.91925  0.79098   1.0000  0.99453
## Pos Pred Value         0.4990  0.51054  0.33951      NaN  0.95245
## Neg Pred Value         0.9405  0.85519  0.88406   0.8361  0.89578
## Prevalence             0.2845  0.19347  0.17436   0.1639  0.18379
## Detection Rate         0.2554  0.06793  0.08871   0.0000  0.08934
## Detection Prevalence   0.5119  0.13306  0.26128   0.0000  0.09381
## Balanced Accuracy      0.7697  0.63518  0.64988   0.5000  0.74033
</code></pre><h3 id="naive-bayes">Naive Bayes</h3>
<p>I selected this approach because I am a big fan of the Bayesian approach in statistical modelling and I wanted to get some practical experience with it.  </p>
<pre><code class="lang-r">nb.fit &lt;- train(classe ~ ., data=subset.for.training, method=<span class="hljs-string">"nb"</span>)
nb.cm &lt;- confusionMatrix(predict.nb, subset.for.testing$classe)
nb.cm
</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1950  309  315  229   79
##          B   46  984   93    2  106
##          C  100  121  895  184   59
##          D  115   59   49  796   69
##          E   21   45   16   75 1129
## 
## Overall Statistics
##                                           
##                Accuracy : 0.7334          
##                  95% CI : (0.7234, 0.7431)
##     No Information Rate : 0.2845          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.6591          
##  Mcnemar&#39;s Test P-Value : &lt; 2.2e-16       
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.8737   0.6482   0.6542   0.6190   0.7829
## Specificity            0.8340   0.9610   0.9284   0.9555   0.9755
## Pos Pred Value         0.6766   0.7994   0.6586   0.7316   0.8779
## Neg Pred Value         0.9432   0.9193   0.9271   0.9275   0.9523
## Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
## Detection Rate         0.2485   0.1254   0.1141   0.1015   0.1439
## Detection Prevalence   0.3673   0.1569   0.1732   0.1387   0.1639
## Balanced Accuracy      0.8538   0.8046   0.7913   0.7872   0.8792
</code></pre><h3 id="random-forest">Random Forest</h3>
<p>I selected this approach out of curiosity to see if it could out preform the Bayesian model.</p>
<pre><code class="lang-r">rf.fit &lt;- train(classe ~ ., data = subset.for.training, method = <span class="hljs-string">'rf'</span>, 
                trControl = trainControl(method = <span class="hljs-string">"cv"</span>, number = <span class="hljs-number">4</span>, allowParallel = <span class="hljs-literal">TRUE</span>), importance=<span class="hljs-literal">TRUE</span>)
predict.rf &lt;- predict(rf.fit, subset.for.testing)
rf.cm &lt;- confusionMatrix(predict.rf, subset.for.testing$classe)
rm.imp &lt;- varImp(rf.fit)
rf.cm
</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 2231   15    0    0    0
##          B    0 1497   16    0    0
##          C    0    6 1349   25    5
##          D    0    0    3 1261    8
##          E    1    0    0    0 1429
## 
## Overall Statistics
##                                          
##                Accuracy : 0.9899         
##                  95% CI : (0.9875, 0.992)
##     No Information Rate : 0.2845         
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16      
##                                          
##                   Kappa : 0.9873         
##  Mcnemar&#39;s Test P-Value : NA             
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9996   0.9862   0.9861   0.9806   0.9910
## Specificity            0.9973   0.9975   0.9944   0.9983   0.9998
## Pos Pred Value         0.9933   0.9894   0.9740   0.9914   0.9993
## Neg Pred Value         0.9998   0.9967   0.9971   0.9962   0.9980
## Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
## Detection Rate         0.2843   0.1908   0.1719   0.1607   0.1821
## Detection Prevalence   0.2863   0.1928   0.1765   0.1621   0.1823
## Balanced Accuracy      0.9984   0.9918   0.9903   0.9894   0.9954
</code></pre><h2 id="model-evaluation">Model Evaluation</h2>
<p><img src="Course_Project_files/figure-html/unnamed-chunk-13-1.png" alt=""> </p>
<p>Because of the high level of accuracy of the random forest model, I chose to use it to predict classify the 20 test cases.</p>
<p>\newpage</p>
<h1 id="appendix-1-features">Appendix 1: Features</h1>
<p><em>roll_belt</em>, <em>pitch_belt</em>, <em>yaw_belt</em>, <em>total_accel_belt</em>, <em>gyros_belt_x</em>, <em>gyros_belt_y</em>, <em>gyros_belt_z</em>, <em>accel_belt_x</em>, <em>accel_belt_y</em>, <em>accel_belt_z</em>, <em>magnet_belt_x</em>, <em>magnet_belt_y</em>, <em>magnet_belt_z</em>, <em>roll_arm</em>, <em>pitch_arm</em>, <em>yaw_arm</em>, <em>total_accel_arm</em>, <em>gyros_arm_x</em>, <em>gyros_arm_y</em>, <em>gyros_arm_z</em>, <em>accel_arm_x</em>, <em>accel_arm_y</em>, <em>accel_arm_z</em>, <em>magnet_arm_x</em>, <em>magnet_arm_y</em>, <em>magnet_arm_z</em>, <em>roll_dumbbell</em>, <em>pitch_dumbbell</em>, <em>yaw_dumbbell</em>, <em>total_accel_dumbbell</em>, <em>gyros_dumbbell_x</em>, <em>gyros_dumbbell_y</em>, <em>gyros_dumbbell_z</em>, <em>accel_dumbbell_x</em>, <em>accel_dumbbell_y</em>, <em>accel_dumbbell_z</em>, <em>magnet_dumbbell_x</em>, <em>magnet_dumbbell_y</em>, <em>magnet_dumbbell_z</em>, <em>roll_forearm</em>, <em>pitch_forearm</em>, <em>yaw_forearm</em>, <em>total_accel_forearm</em>, <em>gyros_forearm_x</em>, <em>gyros_forearm_y</em>, <em>gyros_forearm_z</em>, <em>accel_forearm_x</em>, <em>accel_forearm_y</em>, <em>accel_forearm_z</em>, <em>magnet_forearm_x</em>, <em>magnet_forearm_y</em>, <em>magnet_forearm_z</em> and <em>classe</em></p>
<h1 id="appendix-2-sample-data">Appendix 2: Sample Data</h1>
<table>
<thead>
<tr>
<th style="text-align:center">roll_belt</th>
<th style="text-align:center">pitch_belt</th>
<th style="text-align:center">yaw_belt</th>
<th style="text-align:center">total_accel_belt</th>
<th style="text-align:center">gyros_belt_x</th>
<th style="text-align:center">gyros_belt_y</th>
<th style="text-align:center">gyros_belt_z</th>
<th style="text-align:center">accel_belt_x</th>
<th style="text-align:center">accel_belt_y</th>
<th style="text-align:center">accel_belt_z</th>
<th style="text-align:center">magnet_belt_x</th>
<th style="text-align:center">magnet_belt_y</th>
<th style="text-align:center">magnet_belt_z</th>
<th style="text-align:center">roll_arm</th>
<th style="text-align:center">pitch_arm</th>
<th style="text-align:center">yaw_arm</th>
<th style="text-align:center">total_accel_arm</th>
<th style="text-align:center">gyros_arm_x</th>
<th style="text-align:center">gyros_arm_y</th>
<th style="text-align:center">gyros_arm_z</th>
<th style="text-align:center">accel_arm_x</th>
<th style="text-align:center">accel_arm_y</th>
<th style="text-align:center">accel_arm_z</th>
<th style="text-align:center">magnet_arm_x</th>
<th style="text-align:center">magnet_arm_y</th>
<th style="text-align:center">magnet_arm_z</th>
<th style="text-align:center">roll_dumbbell</th>
<th style="text-align:center">pitch_dumbbell</th>
<th style="text-align:center">yaw_dumbbell</th>
<th style="text-align:center">total_accel_dumbbell</th>
<th style="text-align:center">gyros_dumbbell_x</th>
<th style="text-align:center">gyros_dumbbell_y</th>
<th style="text-align:center">gyros_dumbbell_z</th>
<th style="text-align:center">accel_dumbbell_x</th>
<th style="text-align:center">accel_dumbbell_y</th>
<th style="text-align:center">accel_dumbbell_z</th>
<th style="text-align:center">magnet_dumbbell_x</th>
<th style="text-align:center">magnet_dumbbell_y</th>
<th style="text-align:center">magnet_dumbbell_z</th>
<th style="text-align:center">roll_forearm</th>
<th style="text-align:center">pitch_forearm</th>
<th style="text-align:center">yaw_forearm</th>
<th style="text-align:center">total_accel_forearm</th>
<th style="text-align:center">gyros_forearm_x</th>
<th style="text-align:center">gyros_forearm_y</th>
<th style="text-align:center">gyros_forearm_z</th>
<th style="text-align:center">accel_forearm_x</th>
<th style="text-align:center">accel_forearm_y</th>
<th style="text-align:center">accel_forearm_z</th>
<th style="text-align:center">magnet_forearm_x</th>
<th style="text-align:center">magnet_forearm_y</th>
<th style="text-align:center">magnet_forearm_z</th>
<th style="text-align:center">classe</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1.41</td>
<td style="text-align:center">8.07</td>
<td style="text-align:center">-94.4</td>
<td style="text-align:center">3</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">-0.02</td>
<td style="text-align:center">-21</td>
<td style="text-align:center">4</td>
<td style="text-align:center">22</td>
<td style="text-align:center">-3</td>
<td style="text-align:center">599</td>
<td style="text-align:center">-313</td>
<td style="text-align:center">-128</td>
<td style="text-align:center">22.5</td>
<td style="text-align:center">-161</td>
<td style="text-align:center">34</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">-0.02</td>
<td style="text-align:center">-288</td>
<td style="text-align:center">109</td>
<td style="text-align:center">-123</td>
<td style="text-align:center">-368</td>
<td style="text-align:center">337</td>
<td style="text-align:center">516</td>
<td style="text-align:center">13.05</td>
<td style="text-align:center">-70.49</td>
<td style="text-align:center">-84.87</td>
<td style="text-align:center">37</td>
<td style="text-align:center">0</td>
<td style="text-align:center">-0.02</td>
<td style="text-align:center">0</td>
<td style="text-align:center">-234</td>
<td style="text-align:center">47</td>
<td style="text-align:center">-271</td>
<td style="text-align:center">-559</td>
<td style="text-align:center">293</td>
<td style="text-align:center">-65</td>
<td style="text-align:center">28.4</td>
<td style="text-align:center">-63.9</td>
<td style="text-align:center">-153</td>
<td style="text-align:center">36</td>
<td style="text-align:center">0.03</td>
<td style="text-align:center">0</td>
<td style="text-align:center">-0.02</td>
<td style="text-align:center">192</td>
<td style="text-align:center">203</td>
<td style="text-align:center">-215</td>
<td style="text-align:center">-17</td>
<td style="text-align:center">654</td>
<td style="text-align:center">476</td>
<td style="text-align:center">A</td>
</tr>
<tr>
<td style="text-align:center">1.41</td>
<td style="text-align:center">8.07</td>
<td style="text-align:center">-94.4</td>
<td style="text-align:center">3</td>
<td style="text-align:center">0.02</td>
<td style="text-align:center">0</td>
<td style="text-align:center">-0.02</td>
<td style="text-align:center">-22</td>
<td style="text-align:center">4</td>
<td style="text-align:center">22</td>
<td style="text-align:center">-7</td>
<td style="text-align:center">608</td>
<td style="text-align:center">-311</td>
<td style="text-align:center">-128</td>
<td style="text-align:center">22.5</td>
<td style="text-align:center">-161</td>
<td style="text-align:center">34</td>
<td style="text-align:center">0.02</td>
<td style="text-align:center">-0.02</td>
<td style="text-align:center">-0.02</td>
<td style="text-align:center">-290</td>
<td style="text-align:center">110</td>
<td style="text-align:center">-125</td>
<td style="text-align:center">-369</td>
<td style="text-align:center">337</td>
<td style="text-align:center">513</td>
<td style="text-align:center">13.13</td>
<td style="text-align:center">-70.64</td>
<td style="text-align:center">-84.71</td>
<td style="text-align:center">37</td>
<td style="text-align:center">0</td>
<td style="text-align:center">-0.02</td>
<td style="text-align:center">0</td>
<td style="text-align:center">-233</td>
<td style="text-align:center">47</td>
<td style="text-align:center">-269</td>
<td style="text-align:center">-555</td>
<td style="text-align:center">296</td>
<td style="text-align:center">-64</td>
<td style="text-align:center">28.3</td>
<td style="text-align:center">-63.9</td>
<td style="text-align:center">-153</td>
<td style="text-align:center">36</td>
<td style="text-align:center">0.02</td>
<td style="text-align:center">0</td>
<td style="text-align:center">-0.02</td>
<td style="text-align:center">192</td>
<td style="text-align:center">203</td>
<td style="text-align:center">-216</td>
<td style="text-align:center">-18</td>
<td style="text-align:center">661</td>
<td style="text-align:center">473</td>
<td style="text-align:center">A</td>
</tr>
<tr>
<td style="text-align:center">1.42</td>
<td style="text-align:center">8.07</td>
<td style="text-align:center">-94.4</td>
<td style="text-align:center">3</td>
<td style="text-align:center">0</td>
<td style="text-align:center">0</td>
<td style="text-align:center">-0.02</td>
<td style="text-align:center">-20</td>
<td style="text-align:center">5</td>
<td style="text-align:center">23</td>
<td style="text-align:center">-2</td>
<td style="text-align:center">600</td>
<td style="text-align:center">-305</td>
<td style="text-align:center">-128</td>
<td style="text-align:center">22.5</td>
<td style="text-align:center">-161</td>
<td style="text-align:center">34</td>
<td style="text-align:center">0.02</td>
<td style="text-align:center">-0.02</td>
<td style="text-align:center">-0.02</td>
<td style="text-align:center">-289</td>
<td style="text-align:center">110</td>
<td style="text-align:center">-126</td>
<td style="text-align:center">-368</td>
<td style="text-align:center">344</td>
<td style="text-align:center">513</td>
<td style="text-align:center">12.85</td>
<td style="text-align:center">-70.28</td>
<td style="text-align:center">-85.14</td>
<td style="text-align:center">37</td>
<td style="text-align:center">0</td>
<td style="text-align:center">-0.02</td>
<td style="text-align:center">0</td>
<td style="text-align:center">-232</td>
<td style="text-align:center">46</td>
<td style="text-align:center">-270</td>
<td style="text-align:center">-561</td>
<td style="text-align:center">298</td>
<td style="text-align:center">-63</td>
<td style="text-align:center">28.3</td>
<td style="text-align:center">-63.9</td>
<td style="text-align:center">-152</td>
<td style="text-align:center">36</td>
<td style="text-align:center">0.03</td>
<td style="text-align:center">-0.02</td>
<td style="text-align:center">0</td>
<td style="text-align:center">196</td>
<td style="text-align:center">204</td>
<td style="text-align:center">-213</td>
<td style="text-align:center">-18</td>
<td style="text-align:center">658</td>
<td style="text-align:center">469</td>
<td style="text-align:center">A</td>
</tr>
<tr>
<td style="text-align:center">1.48</td>
<td style="text-align:center">8.05</td>
<td style="text-align:center">-94.4</td>
<td style="text-align:center">3</td>
<td style="text-align:center">0.02</td>
<td style="text-align:center">0</td>
<td style="text-align:center">-0.03</td>
<td style="text-align:center">-22</td>
<td style="text-align:center">3</td>
<td style="text-align:center">21</td>
<td style="text-align:center">-6</td>
<td style="text-align:center">604</td>
<td style="text-align:center">-310</td>
<td style="text-align:center">-128</td>
<td style="text-align:center">22.1</td>
<td style="text-align:center">-161</td>
<td style="text-align:center">34</td>
<td style="text-align:center">0.02</td>
<td style="text-align:center">-0.03</td>
<td style="text-align:center">0.02</td>
<td style="text-align:center">-289</td>
<td style="text-align:center">111</td>
<td style="text-align:center">-123</td>
<td style="text-align:center">-372</td>
<td style="text-align:center">344</td>
<td style="text-align:center">512</td>
<td style="text-align:center">13.43</td>
<td style="text-align:center">-70.39</td>
<td style="text-align:center">-84.87</td>
<td style="text-align:center">37</td>
<td style="text-align:center">0</td>
<td style="text-align:center">-0.02</td>
<td style="text-align:center">-0.02</td>
<td style="text-align:center">-232</td>
<td style="text-align:center">48</td>
<td style="text-align:center">-269</td>
<td style="text-align:center">-552</td>
<td style="text-align:center">303</td>
<td style="text-align:center">-60</td>
<td style="text-align:center">28.1</td>
<td style="text-align:center">-63.9</td>
<td style="text-align:center">-152</td>
<td style="text-align:center">36</td>
<td style="text-align:center">0.02</td>
<td style="text-align:center">-0.02</td>
<td style="text-align:center">0</td>
<td style="text-align:center">189</td>
<td style="text-align:center">206</td>
<td style="text-align:center">-214</td>
<td style="text-align:center">-16</td>
<td style="text-align:center">658</td>
<td style="text-align:center">469</td>
<td style="text-align:center">A</td>
</tr>
<tr>
<td style="text-align:center">1.48</td>
<td style="text-align:center">8.07</td>
<td style="text-align:center">-94.4</td>
<td style="text-align:center">3</td>
<td style="text-align:center">0.02</td>
<td style="text-align:center">0.02</td>
<td style="text-align:center">-0.02</td>
<td style="text-align:center">-21</td>
<td style="text-align:center">2</td>
<td style="text-align:center">24</td>
<td style="text-align:center">-6</td>
<td style="text-align:center">600</td>
<td style="text-align:center">-302</td>
<td style="text-align:center">-128</td>
<td style="text-align:center">22.1</td>
<td style="text-align:center">-161</td>
<td style="text-align:center">34</td>
<td style="text-align:center">0</td>
<td style="text-align:center">-0.03</td>
<td style="text-align:center">0</td>
<td style="text-align:center">-289</td>
<td style="text-align:center">111</td>
<td style="text-align:center">-123</td>
<td style="text-align:center">-374</td>
<td style="text-align:center">337</td>
<td style="text-align:center">506</td>
<td style="text-align:center">13.38</td>
<td style="text-align:center">-70.43</td>
<td style="text-align:center">-84.85</td>
<td style="text-align:center">37</td>
<td style="text-align:center">0</td>
<td style="text-align:center">-0.02</td>
<td style="text-align:center">0</td>
<td style="text-align:center">-233</td>
<td style="text-align:center">48</td>
<td style="text-align:center">-270</td>
<td style="text-align:center">-554</td>
<td style="text-align:center">292</td>
<td style="text-align:center">-68</td>
<td style="text-align:center">28</td>
<td style="text-align:center">-63.9</td>
<td style="text-align:center">-152</td>
<td style="text-align:center">36</td>
<td style="text-align:center">0.02</td>
<td style="text-align:center">0</td>
<td style="text-align:center">-0.02</td>
<td style="text-align:center">189</td>
<td style="text-align:center">206</td>
<td style="text-align:center">-214</td>
<td style="text-align:center">-17</td>
<td style="text-align:center">655</td>
<td style="text-align:center">473</td>
<td style="text-align:center">A</td>
</tr>
<tr>
<td style="text-align:center">1.45</td>
<td style="text-align:center">8.06</td>
<td style="text-align:center">-94.4</td>
<td style="text-align:center">3</td>
<td style="text-align:center">0.02</td>
<td style="text-align:center">0</td>
<td style="text-align:center">-0.02</td>
<td style="text-align:center">-21</td>
<td style="text-align:center">4</td>
<td style="text-align:center">21</td>
<td style="text-align:center">0</td>
<td style="text-align:center">603</td>
<td style="text-align:center">-312</td>
<td style="text-align:center">-128</td>
<td style="text-align:center">22</td>
<td style="text-align:center">-161</td>
<td style="text-align:center">34</td>
<td style="text-align:center">0.02</td>
<td style="text-align:center">-0.03</td>
<td style="text-align:center">0</td>
<td style="text-align:center">-289</td>
<td style="text-align:center">111</td>
<td style="text-align:center">-122</td>
<td style="text-align:center">-369</td>
<td style="text-align:center">342</td>
<td style="text-align:center">513</td>
<td style="text-align:center">13.38</td>
<td style="text-align:center">-70.82</td>
<td style="text-align:center">-84.47</td>
<td style="text-align:center">37</td>
<td style="text-align:center">0</td>
<td style="text-align:center">-0.02</td>
<td style="text-align:center">0</td>
<td style="text-align:center">-234</td>
<td style="text-align:center">48</td>
<td style="text-align:center">-269</td>
<td style="text-align:center">-558</td>
<td style="text-align:center">294</td>
<td style="text-align:center">-66</td>
<td style="text-align:center">27.9</td>
<td style="text-align:center">-63.9</td>
<td style="text-align:center">-152</td>
<td style="text-align:center">36</td>
<td style="text-align:center">0.02</td>
<td style="text-align:center">-0.02</td>
<td style="text-align:center">-0.03</td>
<td style="text-align:center">193</td>
<td style="text-align:center">203</td>
<td style="text-align:center">-215</td>
<td style="text-align:center">-9</td>
<td style="text-align:center">660</td>
<td style="text-align:center">478</td>
<td style="text-align:center">A</td>
</tr>
</tbody>
</table>

</body></html>